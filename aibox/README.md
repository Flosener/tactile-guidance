aibox introduces an automated hand guidance solution that enables grasping of the target objects using tactile bracelet

Two key components of automated hand navigation system are:
1) TaskController class (located in controller.py) - provides basic functionality of using automated hand navigation logic algorithm for a live video stream (by default collected from external camera). Default behaviour is defined by method 'experimental_loop' that, for each subsequent frame, based on output from object detectors and, optionally, object tracker and depth estimator provides guiding signal to the bracelet (i.e., information about position of the hand, target object and their surroundings is translated to vibration commands guiding hand in the specific direction).
2) BraceletController class (located in bracelet.py) - provides implementation of all the functions required for automated hand navigation for a single frame (utilized in TaskController). Default behaviour is defined in the method 'navigate_hand' that processes information about hand and target bounding boxes and based on their relative positions provide guiding signal in specific direction or informs user that object is in front of the hand and can be grasped.